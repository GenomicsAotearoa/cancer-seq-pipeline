// Trial pipeline
// Needs cutdapt, samtools, bwa, picard, java, varscan2, fastqc, bedtools. 
// Annovar script table_annovar.pl is a customised version of that provided with annovar, needs to replace the default version.
//      i.e. you need to install annovar and then replace table_annovar.pl with the copy found with this pipeline
// Report generation function to be added (soon)


bwaIndex="/nesi/project/uoa00595/data/hg19/ucsc.hg19.fasta"
cosmic="/nesi/project/uoa02461/data/cosmicCodingMutations.vcf"
dbSnp150="/nesi/project/uoa02461/data/dbsnp150.vcf"
picardLoc = "/scale_wlg_nobackup/pan_migration/apps/easybuild/RHEL6.3/westmere/software/picard/2.1.0/picard.jar"
bindDir="/nesi/nobackup/uoa02461/data/intermediateFiles/"


qc = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles/qcResults"

    exec """fastqc -t 8 $input1 -o fastqc_out/ > $output1.log""", "qc"
    exec """fastqc -t 8 $input2 -o fastqc_out/ > $output2.log""", "qc"
}

unzip = {

}


trim = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    branch.sample=branch.name
    println "Aligning: $sample"
    transform('trim.gz','trim.gz') {
        exec """singularity run --bind $bindDir cutadapt.sif cutadapt --minimum-length 50 -a AGATCGGAAGAGC -q 30  -o $output1 -p $output2 $input1.fastq.gz $input2.fastq.gz""","trim"

    }
}

align = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    requires type: 'the kind of sample being processed: test or control'
    branch.sample=branch.name
        exec """singularity run --bind $bindDir --bind $bwaIndexDir bwa.sif bwa mem -t $threads -R "@RG\\tID:$sample\\tSM:$sample\\tLB:$sample\\tPL:ILLUMINA" $bwaIndex $input1 $input2 > $output""", "align"
        exec """samtools sort -@12 -O BAM -o $output.bam $output""","align"

    }
}


markDuplicates = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    // we only want to mark duplicates, not remove them. 
    exec "java -jar /opt/nesi/mahuika/picard/2.1.0/picard.jar MarkDuplicates I=$input.bam O=$output.bam M=$output._dup_metrics.txt TMP_DIR='/nesi/project/uoa02461/data/tmp' CREATE_INDEX=TRUE", "markDuplicates"
}

recalibrate = {
    output.dir="/nesi/nobackup/uoa02606/data/intermediateFiles"
    exec """ ../bin/gatk/gatk --java-options "-Xmx16G" BaseRecalibrator -R $bwaIndex -I $input.bam -O $output.table --known-sites /scale_wlg_persistent/filesets/project/uoa02606/data/gatk/dbsnp_138.hg19.vcf --known-sites /scale_wlg_persistent/filesets/project/uoa02606/data/gatk/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf""", "recalibrate"
    exec """ ../bin/gatk/gatk --java-options "-Xmx16G" ApplyBQSR -R $bwaIndex -I $input.bam -bqsr $output.table -O $output.bam""", "recalibrate"

}

haplotypeCalling = {
    output.dir="/nesi/nobackup/uoa02606/data/intermediateFiles"
    exec """/scale_wlg_persistent/filesets/project/uoa02606/bin/gatk/gatk --java-options "-Xmx32G" HaplotypeCaller -R $bwaIndex -I $input.bam -O $output.vcf""" ,"haplotyping"
}


// Do we want to do this?
// ....
// yeah, why not. 
removeSuplementary = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    transform('.bam' ) {
        exec """samtools view -@ $threads -b -F 2048 $input.bam > $output.bam""","removeSupplementary"
        exec """samtools index $output.bam""","removeSupplementary"
    }
    
}

collectMetrics = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles/metrics"
    exec "java -jar /opt/nesi/mahuika/picard/2.1.0/picard.jar CollectInsertSizeMetrics I=$input O=$output.sampleMetrics.txt H=$output.sampleHist.pdf M=0.5","collectMetrics"
}

convertToSam = {
        output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
        exec "samtools view -h -o $output.sam $input.bam", "convertToSam"
}



filterShortInserts = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    //exec "awk -F '\t' '((\$1~/@/) || (\$9 <= -50 && \$9 >= -150) || (\$9 <= 150 && \$9 >= 50)) { print \$0 }' $input.sam > $output.sam"
    exec "awk '{ print \$1 '\t' \$2 }' "

}

convertToBam = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    exec "samtools view -S -b input.sam > output.bam"
}


pileUp = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    branch.sample = branch.name
   
    from(sample + '*.bam') {
        exec """samtools mpileup -P $threads -B -d 9001 -q 1 -f $bwaIndex  $input.control.bam $input.test.bam | java -Xmx16g -d64 -jar /nesi/project/uoa00571/bin/VarScan.v2.4.3.jar somatic --mpileup 1 --min-var-freq 0.1 --p-value 1.00 --somatic-p-value 1.00 --strand-filter 0 --tumor-purity 0.5 --output-vcf 1 --min-coverage-normal 10 --min-coverage-tumor 10 --output-snp $output1.snp.vcf  --output-indel $output1.indel.vcf""","pileUp"

    }
}




// filter out mutations found in dbsnp150
filterdbSnp150 = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    exec "bedtools intersect -v  -a $input.vcf -b $dbSnp150 > $output.vcf"
}

removeDuplicates = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    transform('.bam', '._dup_metrics.txt') {
        exec """java -jar  $picardLoc MarkDuplicates I=$input.bam O=$output.bam M=$output._dup_metrics.txt REMOVE_DUPLICATES=TRUE CREATE_INDEX=TRUE""", "removeDuplicates"
    }
}

alignmentMetrics = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    exec """ samtools index -@ $threads $input.bam > $output.indexed""" , "index"
    exec """ java -Xmx8G -jar /nesi/project/uoa00571/bin/GenomeAnalysisTK.jar -T DepthOfCoverage -I $input.bam -R /nesi/project/uoa02461/data/hg19/ucsc.hg19.fasta -o $output  --omitDepthOutputAtEachBase --omitIntervalStatistics --omitLocusTable --printBaseCounts -L /nesi/project/uoa00571/data/design_files/S07604514_Regions.bed -ct 1 -ct 10 -ct 30 -ct 50 -ct 100 -ct 200 > $output """, "alignmentMetrics"
    exec """ java -Xmx8G -jar $picardLoc CollectAlignmentSummaryMetrics I=$input.bam R=$bwaIndex O=$output.AlignmentMetricsLog""" , "alignmentMetrics"
}


// filter with cosmic mutations - keep anything that is in either cosmic coding or cosmic non-coding vcf's
filterCosmic = {
    output.dir="/nesi/nobackup/uoa02461/data/intermediateFiles"
    exec "bedtools intersect  -a $input.vcf -b $cosmic > $output.vcf"
}


count = {
  output.dir = "/nesi/nobackup/uoa02461/data/intermediateFiles"
  exec "module load R"
  exec "echo $input"
  exec "Rscript serial.R $input snp $output $output2"
  // then the germline one exec
}


def branches = [
sample1: ["/nesi/nobackup/uoa02461/data/intermediateFiles/A0028-1_1.fastq.gz.align.removeDuplicates.removeSuppplementary.bam" ,"/nesi/nobackup/uoa02461/data/intermediateFiles/A0028B_1.fastq.gz.align.removeDuplicates.removeSuppplementary.bam"],
sample2: ["/nesi/nobackup/uoa02461/data/intermediateFiles/A0028-2_1.fastq.gz.align.removeDuplicates.removeSuppplementary.bam", "/nesi/nobackup/uoa02461/data/intermediateFiles/A0028B_1.fastq.gz.align.removeDuplicates.removeSuppplementary.bam" ]
]


// currently runs qc, doesn't wait for confirmation on whether to continue the run, 
// trims, and does a 2nd lot of qc to the trimmed reads. 
// Once this is parrallelized, should be able to insert multiqc steps. 

// run with qc
//run { [qc + trim] +  [qc + align] + removeDuplicates + removeSuppplementary + pileUp + variantCalling + annotation}

// actual plasma run ...
//run { trim +  align + markDuplicates + removeSuppplementary +  convertToSam + filterShortInserts + convertToBam + pileUp + variantCalling + annotation + filterdbSnp150 + filterCosmic}
//run {
//   "%_*.fastq.gz" * [trim] + "%_*.trim" * [align] + "%_*" * [removeDuplicates] + "%_*" * [removeSuppplementary] + branches * [pileUp] +  "%_*" * [annotation]
//}

//run { "%_*.fastq.gz" * [trim]  + "%_*.trim" * [align] + "%_*" * [removeDuplicates, alignmentMetrics] }

